{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c859da18-018c-4afe-b989-919dfc93d5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time, sys, os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchsummary import summary\n",
    "import tqdm\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from compression_nn.preprocess_multi_piece import prepare_data_for_training\n",
    "from compression_nn.compression_nn import CompressionNN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1f0486-d847-4244-99f2-e183e88d3df5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available\n"
     ]
    }
   ],
   "source": [
    "# use GPUs if available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Available\")\n",
    "    device = torch.device('cuda')\n",
    "    use_cuda=True\n",
    "else:\n",
    "    print('CUDA Not Available')\n",
    "    device = torch.device('cpu')\n",
    "    use_cuda=False\n",
    "cudnn.benchmark = True      #May train faster but cost more memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a40e21-a306-4565-82e3-aa38ff838e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STATS = 'WL_23_WPH_short_CMBWL'\n",
    "\n",
    "GAUSSIAN_AUG_STRENTH = 0.1\n",
    "BATCH_SIZE           = 16\n",
    "LEARNING_RATE        = 0.0005\n",
    "NUM_EPOCH            = 300\n",
    "WEIGHT_DECAY_RATE    = 0.01\n",
    "SCHEDULER_FACTOR     = 0.3\n",
    "SCHEDULER_PATIENCE   = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8b4ce1-7d9f-4448-83d0-b6d7c6529317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WL_3_WPH_short\n",
      "WL_23_WPH_short\n",
      "WL_23_WPH_short_CMBWL\n",
      "WPH\n",
      "CMBWL\n"
     ]
    }
   ],
   "source": [
    "DD = np.load('/global/cfs/cdirs/des/mgatti/CMB_lensing/DV/SBI_forecast/compression/compression_data_combined.npy',allow_pickle=True).item()\n",
    "stat = DD['stat']\n",
    "mask = DD['mask']\n",
    "target = DD['data']\n",
    "\n",
    "# wph get rid of stuff that's degenerate with wl2 and wl3\n",
    "# this defines \"WPH_short\"\n",
    "mask_l = np.array(16*[ True,  True,  True,  True, False, False,  True,  True,  True,\n",
    "        True,  True,  True, False, False, False, False,  True,  True,\n",
    "        True,  True, False, False, False, False,  True,  True, False,\n",
    "       False, False, False, False, False, False, False, False, False])\n",
    "mask_nbody_wph = np.hstack([np.array([False]*60),np.array([False]*120),mask_l])\n",
    "\n",
    "# these keys are DVs that don't exist. \n",
    "# These indices are defined to select from their corresponding odict ('original dictionary') DVs that do exist\n",
    "indict2 = dict()\n",
    "indict2['WL_23_WPH_short'] = np.concatenate( ( list( range(320) ), np.array( range(320, 1076))[mask_nbody_wph]) )\n",
    "indict2['WL_3_WPH_short'] = np.concatenate( ( list( range(160, 320) ), np.array( range(320, 1076))[mask_nbody_wph]) )\n",
    "indict2['WL_23_WPH_short_CMBWL'] = np.concatenate( ( list( range(320) ), np.array( range(320, 1076))[mask_nbody_wph], list(range(1076, 1108) )) )\n",
    "indict2['WPH'] = np.array( range(160, 916))[mask_nbody_wph]\n",
    "indict2['CMBWL'] = range(160, 192)\n",
    "\n",
    "odict = dict()\n",
    "odict['WL_3_WPH_short'] = 'WL_23_WPH'\n",
    "odict['WL_23_WPH_short'] = 'WL_23_WPH'\n",
    "odict['WL_23_WPH_short_CMBWL'] = 'WL_23_WPH_WCMBL'\n",
    "odict['WPH'] = 'WL_2_WPH'\n",
    "odict['CMBWL'] = 'WL_2_WCMBL'\n",
    "\n",
    "for key in odict.keys():\n",
    "    print(key)\n",
    "    stat[key] = stat[odict[key]].copy()\n",
    "    stat[key]['dv'] = stat[key]['dv'][:,indict2[key]]\n",
    "        \n",
    "\n",
    "swapind = np.array([0,1,2,3,4,13,14,15,9,10,11,12,5,6,7,8,16])   # om s8 w a e .    ob ns h ...   dm dz\n",
    "\n",
    "for key in stat.keys():\n",
    "    stat[key]['params'] = stat[key]['params'][:,swapind]\n",
    "\n",
    "# defining additional_mask that filters away some extreme values of w, A, eta\n",
    "parms = stat['WL_2']['params']\n",
    "extra =   (parms[:,3]<0.8)  & (parms[:,3]>0.2) &\\\n",
    "         (parms[:,4]>0.1) &   (parms[:,4]<0.9) \n",
    "\n",
    "additional_mask = (stat['WL_2']['params'][:,2]>0.1)&extra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edf733d-d9d1-479c-8467-aca9fdfb3768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# these are the pars/DV that will be used to train the compression (or whatever pre-processing).\n",
    "pars_train = np.array(stat[STATS]['params'][mask&additional_mask,:16])\n",
    "dv = np.array(stat[STATS]['dv'][mask&additional_mask,:])\n",
    "\n",
    "    # these are the pars/DV that will be used for the LFI step later on \n",
    "    # (so you apply whatever compression/preprocessing to these and give to NDE)\n",
    "pars_LFI = np.array(stat[STATS]['params'][(~mask)&additional_mask,:16])\n",
    "dv_LFI = np.array(stat[STATS]['dv'][(~mask)&additional_mask,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f25c4-2915-4f9a-9698-6ed40f7419de",
   "metadata": {},
   "source": [
    "# Process data; with ZCA whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2128fc-a0fb-40d5-9fb8-ad10e3632967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no normalization\n",
    "\n",
    "# train only on OMM and S8\n",
    "pars_train = pars_train[:, 0:2]\n",
    "pars_LFI = pars_LFI[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d1370c-1c8e-4138-9cbd-5745cf7585c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_samples = len(pars_train)\n",
    "# split the sample for training ----------\n",
    "train_split, val_split = int(0.9*num_samples), int(0.1*num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d99243-3e6c-483e-a6de-a6a85a51c473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "train_loader, val_loader, test_loader, zca = prepare_data_for_training(\n",
    "    train_x=dv[:train_split],\n",
    "    train_y=pars_train[:train_split],\n",
    "    val_x=dv[train_split:],\n",
    "    val_y=pars_train[train_split:],\n",
    "    test_x=dv_LFI,\n",
    "    test_y=pars_LFI,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    whitening = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b499c3ae-fcf3-40d7-b6e4-0fcbf7efd558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7feb03fc5160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0eb229-4d11-4a30-ad57-1190dcdda6f9",
   "metadata": {},
   "source": [
    "# Start Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb83ed2-e0a3-4404-aa37-c236c91d7c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f62f5-9ce7-4f8f-83fb-d30c068b60af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
